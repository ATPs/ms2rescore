import importlib.resources
import json
import logging
from datetime import datetime
from itertools import cycle
from pathlib import Path
from typing import Dict, Optional

import pandas as pd
import plotly.express as px
import psm_utils.io
import tomlkit
from jinja2 import Environment, FileSystemLoader
from psm_utils.psm_list import PSMList

import ms2rescore
import ms2rescore.report.charts as charts
import ms2rescore.report.templates as templates
from ms2rescore.report.utils import get_confidence_estimates, read_feature_names

logger = logging.getLogger(__name__)

PLOTLY_HTML_KWARGS = {
    "full_html": False,
    "include_plotlyjs": False,
    "include_mathjax": False,
    "config": {
        "displayModeBar": True,
        "displaylogo": False,
    },
}


with importlib.resources.open_text(templates, "texts.toml") as f:
    TEXTS = tomlkit.load(f)


def generate_report(output_path_prefix: str, psm_list: Optional[psm_utils.PSMList] = None):
    """Generate report."""
    files = _collect_files(output_path_prefix)

    # Read PSMs
    if not psm_list:
        logger.info("Reading PSMs...")
        psm_list = psm_utils.io.read_file(files["PSMs"], filetype="tsv", show_progressbar=True)
    elif not files["PSMs"]:
        raise FileNotFoundError("PSM file not found and no PSM list provided.")

    # Read config
    config = json.loads(files["configuration"].read_text())

    logger.info("Recalculating confidence estimates...")
    # fasta_file = config["ms2rescore"]["fasta_file"]  # TODO Update if changed upstream
    fasta_file = config["ms2rescore"]["rescoring_engine"]["mokapot"]["fasta_file"]
    confidence_before, confidence_after = get_confidence_estimates(psm_list, fasta_file)

    overview_context = _get_overview_context(confidence_before, confidence_after)
    target_decoy_context = _get_target_decoy_context(psm_list)
    features_context = _get_features_context(psm_list, files)
    config_context = _get_config_context(config)

    logger.info("Collecting content...")
    context = {
        "metadata": {
            "generated_on": datetime.now().strftime("%d/%m/%Y %H:%M:%S"),
            "ms2rescore_version": ms2rescore.__version__,  # TODO: Write during run?
            "psm_filename": Path(config["ms2rescore"]["psm_file"]).name,
        },
        "main_tabs": [
            {
                "id": "main_tab_comparison",
                "title": "Overview",
                "template": "overview.html",
                "context": overview_context,
            },
            {
                "id": "main_tab_target_decoy",
                "title": "Target/decoy evaluation",
                "template": "target-decoy.html",
                "context": target_decoy_context,
            },
            {
                "id": "main_tab_features",
                "title": "Rescoring features",
                "template": "features.html",
                "context": features_context,
            },
            {
                "id": "main_tab_config",
                "title": "Full configuration",
                "template": "config.html",
                "context": config_context,
            },
            {
                "id": "main_tab_log",
                "title": "Log",
                "template": "log.html",
                "context": {"log": files["log"].read_text(encoding="utf-8")},
            },
        ],
    }

    _render_and_write(output_path_prefix, **context)


def _collect_files(output_path_prefix):
    """Collect all files generated by MS²Rescore."""
    logger.info("Collecting files...")
    required_files = ["PSMs"]
    files = {
        "PSMs": Path(output_path_prefix + ".ms2rescore.psms.tsv").resolve(),
        "configuration": Path(output_path_prefix + ".ms2rescore.full-config.json").resolve(),
        "feature names": Path(output_path_prefix + ".ms2rescore.feature_names.tsv").resolve(),
        "feature weights": Path(output_path_prefix + ".ms2rescore.mokapot.weights.tsv").resolve(),
        "log": Path(output_path_prefix + ".ms2rescore.log.html").resolve(),
    }
    for file, path in files.items():
        if Path(path).is_file():
            logger.info("✅ Found %s: '%s'", file, path.as_posix())
        elif file in required_files:
            raise FileNotFoundError(f"Required file not found: '{path.as_posix()}'")
        else:
            logger.warning("❌ %s: '%s'", file, path.as_posix())
            files[file] = None
    return files


def _get_stats_context(confidence_before, confidence_after):
    """Return context for overview statistics pane."""
    stats = []
    levels = ["psms", "peptides", "proteins"]
    level_names = ["PSMs", "Peptides", "Protein groups"]
    card_colors = ["card-bg-blue", "card-bg-green", "card-bg-red"]
    for level, level_name, card_color in zip(levels, level_names, card_colors):
        try:
            before = confidence_before.accepted[level.lower()]
            after = confidence_after.accepted[level.lower()]
        except KeyError:
            continue  # Level not present (e.g. no fasta provided)
        increase = (after - before) / before * 100
        stats.append(
            {
                "item": level_name,
                "card_color": card_color,
                "number": after,
                "diff": f"{after - before:+}",
                "percentage": f"{increase:.1f}%",
                "is_increase": increase > 0,
                "bar_percentage": before / after * 100 if increase > 0 else after / before * 100,
                "bar_color": "#24a143" if increase > 0 else "#a12424",
            }
        )
    return stats


def _get_overview_context(confidence_before, confidence_after) -> dict:
    """Return context for overview tab."""
    logger.info("Generating overview charts...")
    return {
        "stats": _get_stats_context(confidence_before, confidence_after),
        "charts": [
            {
                "title": TEXTS["charts"]["score_comparison"]["title"],
                "description": TEXTS["charts"]["score_comparison"]["description"],
                "chart": charts.score_scatter_plot(
                    confidence_before,
                    confidence_after,
                ).to_html(**PLOTLY_HTML_KWARGS),
            },
            {
                "title": TEXTS["charts"]["fdr_comparison"]["title"],
                "description": TEXTS["charts"]["fdr_comparison"]["description"],
                "chart": charts.fdr_plot_comparison(
                    confidence_before,
                    confidence_after,
                ).to_html(**PLOTLY_HTML_KWARGS),
            },
            {
                "title": TEXTS["charts"]["identification_overlap"]["title"],
                "description": TEXTS["charts"]["identification_overlap"]["description"],
                "chart": charts.identification_overlap(
                    confidence_before,
                    confidence_after,
                ).to_html(**PLOTLY_HTML_KWARGS),
            },
        ],
    }


def _get_target_decoy_context(psm_list) -> dict:
    # fasta_file = "../../examples/fasta/uniprot-proteome-human-contaminants.fasta"
    # confidence_estimates = _get_confidence_estimates(psm_list, fasta_file)
    logger.info("Generating target-decoy charts...")
    psm_df = psm_list.to_dataframe()
    return {
        "charts": [
            {
                "title": TEXTS["charts"]["score_histogram"]["title"],
                "description": TEXTS["charts"]["score_histogram"]["description"],
                "chart": charts.score_histogram(psm_df).to_html(**PLOTLY_HTML_KWARGS),
            },
            {
                "title": TEXTS["charts"]["pp_plot"]["title"],
                "description": TEXTS["charts"]["pp_plot"]["description"],
                "chart": charts.pp_plot(psm_df).to_html(**PLOTLY_HTML_KWARGS),
            },
        ]
    }


def _get_config_context(config: dict) -> dict:
    """Return context for config tab."""
    return {
        "description": TEXTS["configuration"]["description"],
        "config": json.dumps(config, indent=4),
    }


def _get_features_context(psm_list: PSMList, files: Dict[str, Path]) -> dict:
    """Return context for features tab."""
    logger.info("Generating feature-related charts...")
    context = {"charts": []}

    # Get feature names, mapping with generator, and flat list
    feature_names = read_feature_names(files["feature names"])
    feature_names_flat = [f_name for f_list in feature_names.values() for f_name in f_list]
    feature_names_inv = {name: gen for gen, f_list in feature_names.items() for name in f_list}

    # Get fixed color map for feature generators
    color_map = dict(zip(feature_names.keys(), cycle(px.colors.qualitative.Plotly)))

    # feature weights
    if not files["feature weights"]:
        logger.warning("Could not find feature weights files. Skipping feature weights plot.")
    else:
        feature_weights = pd.read_csv(files["feature weights"], sep="\t").melt(
            var_name="feature", value_name="weight"
        )
        feature_weights["feature_generator"] = feature_weights["feature"].map(feature_names_inv)
        context["charts"].append(
            {
                "title": TEXTS["charts"]["feature_usage"]["title"],
                "description": TEXTS["charts"]["feature_usage"]["description"],
                "chart": charts.feature_weights_by_generator(
                    feature_weights, color_discrete_map=color_map
                ).to_html(**PLOTLY_HTML_KWARGS)
                + charts.feature_weights(feature_weights, color_discrete_map=color_map).to_html(
                    **PLOTLY_HTML_KWARGS
                ),
            }
        )

    # Individual feature performance
    features = charts.get_feature_values(psm_list, feature_names_flat)
    _, feature_ecdf_auc = charts.calculate_feature_qvalues(features, psm_list["is_decoy"])
    feature_ecdf_auc["feature_generator"] = feature_ecdf_auc["feature"].map(feature_names_inv)

    context["charts"].append(
        {
            "title": TEXTS["charts"]["feature_performance"]["title"],
            "description": TEXTS["charts"]["feature_performance"]["description"],
            "chart": charts.feature_ecdf_auc_bar(
                feature_ecdf_auc, color_discrete_map=color_map
            ).to_html(**PLOTLY_HTML_KWARGS),
        }
    )

    return context


def _render_and_write(output_path_prefix: str, **context):
    """Render template with context and write to HTML file."""
    report_path = Path(output_path_prefix + ".ms2rescore.report.html").resolve()
    logger.info("Writing report to %s", report_path.as_posix())
    template_dir = Path(__file__).parent / "templates"
    env = Environment(loader=FileSystemLoader(template_dir, encoding="utf-8"))
    template = env.get_template("base.html")
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(template.render(**context))
